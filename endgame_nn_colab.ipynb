{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "endgame_nn_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SleepyBob/endgame-nn-colab/blob/main/endgame_nn_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM4vxR736Unx"
      },
      "source": [
        "Note: you need to upload the training data and/or syzygy files to the notebook before running this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNyjphEJ8WrU",
        "outputId": "be35564e-eee7-450e-99da-b905ca9ff5c6"
      },
      "source": [
        "!pip install chess\n",
        "#import chess\n",
        "#print(chess.__version__)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chess in /usr/local/lib/python3.7/dist-packages (1.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z43jBp__2ZsJ",
        "outputId": "bfab2208-039a-4d37-c6bf-7a0d684e942e"
      },
      "source": [
        "# Import relevant modules\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import chess\n",
        "import chess.syzygy\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "#import import_data as imp\n",
        "#import train_model as train\n",
        "#import define_model as defmod\n",
        "#import graph as gr\n",
        "#import gen_pos as gp\n",
        "print(chess.__version__)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkvF3nRn22AP"
      },
      "source": [
        "Graph.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bndt8WpC2Pxl"
      },
      "source": [
        "# this file is where graphing functions will go\n",
        "\n",
        "# We can use this to plot the training loss over time\n",
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "    \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"\n",
        "    # list_of_metrics should be one of the names shown in:\n",
        "    # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Value\")\n",
        "\n",
        "    for m in list_of_metrics:\n",
        "        x = hist[m]\n",
        "        plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5XpEqaH2pgs"
      },
      "source": [
        "gen_pos.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxp2eQxL2tKA"
      },
      "source": [
        "def gen_fen(material):\n",
        "    \"\"\"Return a board with the specific material balance\"\"\"\"\"\n",
        "    # Step 1: Create a blank board with either white or black to move\n",
        "    # We are assuming no castling or ep capture will be possible\n",
        "    if random.randint(0, 1) == 1:\n",
        "        board = chess.Board('8/8/8/8/8/8/8/8 w - - 0 1')\n",
        "    else:\n",
        "        board = chess.Board('8/8/8/8/8/8/8/8 b - - 0 1')\n",
        "\n",
        "    # Step 2: Decide whether the first group of material is for white or black\n",
        "    if random.randint(0, 1) == 1:\n",
        "        material = material.swapcase()\n",
        "\n",
        "    # Step 3: Loop over material and add it to the board\n",
        "    dest_squares = random.sample(range(64), len(material))\n",
        "    for piece in material:\n",
        "        location = dest_squares.pop()\n",
        "        board.set_piece_at(location, chess.Piece.from_symbol(piece))\n",
        "    # Step 4: Check that the position is valid\n",
        "    if not board.is_valid() or board.is_checkmate() or board.is_stalemate():\n",
        "        # Recursively get a new try\n",
        "        board = gen_fen(material)\n",
        "    return board\n",
        "\n",
        "\n",
        "def is_white_square(square):\n",
        "    \"\"\"Returns True if the square is on the 'white' diagonals\"\"\"\n",
        "    file = chess.square_file(square)\n",
        "    rank = chess.square_rank(square)\n",
        "    if (file + rank) % 2 == 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def board_to_plane(board):\n",
        "    \"\"\"Takes a board position and translates it into a plane of binary values\"\"\"\n",
        "    \"\"\"Old code that returned a vector\"\"\"\n",
        "    # 0-63,448-511: bishop on dark squares    PNBRQK == 123456\n",
        "    # 64- 512-:  black pawns, white pawns     white = True, black = False\n",
        "    # 128- 576-: knight\n",
        "    # 192- 640-: bishop on light squares\n",
        "    # 256- 704-: rook\n",
        "    # 320- 768-: queen\n",
        "    # 384- 832-895: king\n",
        "    # The location of a square is described by:\n",
        "    # 448*(color white=1 black=0) + 64*(piecetype 1-6) + square\n",
        "    #     - 64*3*is_a_bishop*is_on_light_square\n",
        "    # 896-961 : side to move color (white = 1s)\n",
        "    plane = np.zeros(896, dtype=int)\n",
        "    for square in range(64):\n",
        "        piece_type = board.piece_type_at(square)\n",
        "        if piece_type is None:\n",
        "            pass\n",
        "        else:\n",
        "            if board.color_at(square) == chess.WHITE:\n",
        "                piece_color = 1\n",
        "            else:\n",
        "                piece_color = 0\n",
        "            index = 448 * piece_color + 64 * (piece_type - 1) + square\n",
        "            if piece_type == chess.BISHOP:\n",
        "                # Bishops on white diagonals go in the 0 index instead of 3.\n",
        "                index = index - 64 * 3 * is_white_square(square)\n",
        "            plane[index] = 1\n",
        "    if board.turn == chess.WHITE:\n",
        "        col = np.ones(64)\n",
        "    else:\n",
        "        col = np.zeros(64)\n",
        "    # print(plane)\n",
        "    plane2 = np.concatenate((plane, col))\n",
        "    return plane2\n",
        "\n",
        "\n",
        "def board_to_planev1(board):\n",
        "    \"\"\"Takes a board position and translates it into a planes of binary values\"\"\"\n",
        "    \"\"\"New code retains the 8x8 planes\"\"\"\n",
        "    # The resulting plane will be (8,8,15) - apparently tensorflow prefers channels last\n",
        "    # 0, 7: bishop on dark squares    PNBRQK == 123456\n",
        "    # 1- 8-:  black pawns, white pawns     white = True, black = False\n",
        "    # 2- 9-: knight\n",
        "    # 3- 10-: bishop on light squares\n",
        "    # 4- 11-: rook\n",
        "    # 5- 12-: queen\n",
        "    # 6- 13 : king\n",
        "    # 14    : color white = 1\n",
        "    # The location of a square is described by:\n",
        "    # 448*(color white=1 black=0) + 64*(piecetype 1-6) + square\n",
        "    #     - 64*3*is_a_bishop*is_on_light_square\n",
        "    # 896-961 : side to move color (white = 1s)\n",
        "    plane = np.zeros((8, 8, 15), dtype=int)\n",
        "    for square in range(64):\n",
        "        piece_type = board.piece_type_at(square)\n",
        "        if piece_type is None:\n",
        "            pass\n",
        "        else:\n",
        "            if board.color_at(square) == chess.WHITE:\n",
        "                piece_color = 1\n",
        "            else:\n",
        "                piece_color = 0\n",
        "            file = chess.square_file(square)\n",
        "            rank = chess.square_rank(square)\n",
        "            index = 7 * piece_color + piece_type -1\n",
        "            if piece_type == chess.BISHOP:\n",
        "                # Bishops on white diagonals go in the 0/7 index instead of 3/10.\n",
        "                index = index - 3 * is_white_square(square)\n",
        "\n",
        "            plane[rank, file, index] = 1\n",
        "    if board.turn == chess.WHITE:\n",
        "        col = 1\n",
        "    else:\n",
        "        col = 0\n",
        "    plane[:, :, 14] = col\n",
        "    return plane\n",
        "\n",
        "\n",
        "def board_label(board):\n",
        "    \"\"\"Returns the training labels for the board from Syzygy lookup\"\"\"\n",
        "    # 0 draw for side-to-move, 1 win for side-to-move (more than 50 moves), 2 win for side-to-move\n",
        "    # -1 loss in more than 50, -2 loss in <50\n",
        "    with chess.syzygy.open_tablebase(\"./\") as tablebase:\n",
        "        # board = chess.Board(\"8/2K5/4B3/3N4/8/8/4k3/8 b - - 0 1\")\n",
        "        wdl = tablebase.probe_wdl(board)\n",
        "\n",
        "    # 0 draw, x win in x, -x loss in x\n",
        "    # counts may be off by 1\n",
        "    with chess.syzygy.open_tablebase(\"./\") as tablebase:\n",
        "        # board = chess.Board(\"8/2K5/4B3/3N4/8/8/4k3/8 b - - 0 1\")\n",
        "        dtz = tablebase.probe_dtz(board)\n",
        "    if wdl == 0:\n",
        "        win = 0\n",
        "        draw = 1\n",
        "        loss = 0\n",
        "    elif wdl > 0:\n",
        "        win = 1\n",
        "        draw = 0\n",
        "        loss = 0\n",
        "    else:\n",
        "        win = 0\n",
        "        draw = 0\n",
        "        loss = 1\n",
        "    if dtz > 0:\n",
        "        quality = 2000 - dtz\n",
        "    elif dtz < 0:\n",
        "        quality = -2000 - dtz\n",
        "    else:\n",
        "        quality = 0\n",
        "\n",
        "    return win, draw, loss, quality\n",
        "\n",
        "\n",
        "def adjust_case(input_str):\n",
        "    \"\"\"This converts endgame descriptors so that the first block is capitalized\"\"\"\n",
        "    \"\"\"and the second block is lowercase.  e.g.  krpkq to KRPkq\"\"\"\n",
        "    lower = input_str.lower()\n",
        "    second_k = lower.find(\"k\", 1)\n",
        "    # print(f\"second k at {second_k}\")\n",
        "    out1 = lower[:second_k].upper()\n",
        "    out2 = lower[second_k:]\n",
        "    output_str = out1+out2\n",
        "    if second_k == -1:\n",
        "        output_str = \"fail\"\n",
        "    return output_str\n",
        "\n",
        "\n",
        "def ask_for_input():\n",
        "    need_input = True\n",
        "    while need_input:\n",
        "        balance = input(\"Please enter the endgame (e.g. KRkp): \")\n",
        "        balance = adjust_case(balance)\n",
        "        # print(f\"After Adjusting: {balance}\")\n",
        "        number = int(input(\"Please enter the number of training examples: \"))\n",
        "        if number > 0:\n",
        "            need_input = False\n",
        "        if balance == \"fail\":\n",
        "            need_input = True\n",
        "        if need_input:\n",
        "            print(\"There was a problem with the inputs.\")\n",
        "\n",
        "    return balance, number\n",
        "\n",
        "\n",
        "def generate_training():\n",
        "    material_balance, target_count = ask_for_input()\n",
        "    plane_version = 'v1'\n",
        "    # Note: it took about 1:30 to generate 10,000 positions\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in range(target_count):\n",
        "        my_board = gen_fen(material_balance)\n",
        "        my_plane = board_to_planev1(my_board)\n",
        "        my_label = board_label(my_board)\n",
        "        X_train.append(my_plane)\n",
        "        y_train.append(my_label)\n",
        "        # print a progress bar\n",
        "        if i%1000 == 0:\n",
        "          print(i,end=' ')\n",
        "    print(\"done\")\n",
        "    # Converts from a list to an array at the end; faster than concat array\n",
        "    X_train = np.stack(X_train, axis=0)\n",
        "    y_train = np.stack(y_train, axis=0)\n",
        "    print(X_train.shape)\n",
        "    print(y_train.shape)\n",
        "    print(\"frequency list:\")\n",
        "    unique_elements, counts_elements = np.unique(y_train[:, 3], return_counts=True)\n",
        "    print(\"Frequency of unique values of the said array:\")\n",
        "    print(np.asarray((unique_elements, counts_elements)))\n",
        "\n",
        "    outfile = \"train_\"+material_balance.lower()+str(int(target_count/1000))+\"K\"+plane_version+\".npz\"\n",
        "    # Save as a compressed npz file\n",
        "    np.savez_compressed(outfile, X_train=X_train, y_train=y_train)\n",
        "    print(f\"Data saved to {outfile}\")\n",
        "\n",
        "    # test that we can read the data\n",
        "    # print(\"Doing a test read of the data\")\n",
        "    # npzfile2 = np.load(outfile)\n",
        "    #    print(\"npz variables\")\n",
        "    #    print(npzfile.files)\n",
        "    #    print(npzfile['y_train'])\n",
        "    # X_t2 = npzfile2['X_train']\n",
        "    # y_t2 = npzfile2['y_train']\n",
        "    # print(X_t2.shape)\n",
        "    # print(y_t2.shape)\n",
        "    #print(y_t2)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCYMlivD3B_h"
      },
      "source": [
        "import_data.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PupSBhQ3DTs"
      },
      "source": [
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def import_endgame(filename):\n",
        "    npzfile2 = np.load(filename)\n",
        "    #    print(\"npz variables\")\n",
        "    #    print(npzfile.files)\n",
        "    #    print(npzfile['y_train'])\n",
        "    X_train = npzfile2['X_train']\n",
        "    y_train = npzfile2['y_train']\n",
        "\n",
        "    # Converting time to mate back to an number (0,x)\n",
        "    y_train[y_train[:, 3] < 0, 3] = (-2000 - y_train[y_train[:, 3] < 0, 3]) / 2\n",
        "    y_train[y_train[:, 3] > 0, 3] = (2001 - y_train[y_train[:, 3] > 0, 3]) / 2\n",
        "    y_train[:, 3] += 16\n",
        "\n",
        "    # Or, convert the int values into floats, this doesn't seem to matter\n",
        "    # X_train = X_train.astype(float)\n",
        "    # y_train = y_train.astype(float)\n",
        "\n",
        "    print(\"frequency list:\")\n",
        "    unique_elements, counts_elements = np.unique(y_train[:, 3], return_counts=True)\n",
        "    print(\"Frequency of unique values of the said array:\")\n",
        "    print(np.asarray((unique_elements, counts_elements)))\n",
        "    return X_train, y_train"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQZjrZND3o12"
      },
      "source": [
        "define_model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Lyc-vI3rQ2"
      },
      "source": [
        "def create_model_eg1(my_learning_rate):\n",
        "    \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "    # This is a first try to get a simple model that works\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(8, 8, 15)))\n",
        "    model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=1))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
        "                  loss=\"mean_squared_error\",\n",
        "                  metrics=['MeanSquaredError'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_model_eg5(my_learning_rate):\n",
        "    \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "    # This is a first try to get a simple model that works\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(8, 8, 15)))\n",
        "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=1))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
        "                  loss=\"mean_squared_error\",\n",
        "                  metrics=['MeanSquaredError'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_eg_bin3orig(my_learning_rate):\n",
        "    \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "    # This is a first try to get a simple model that works\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=128, kernel_size=(3,3), input_shape=(8,8,15), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=128, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=33))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_model_eg_bin3(my_learning_rate):\n",
        "    \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "    # This is a first try to get a simple model that works\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=128, kernel_size=(3,3), input_shape=(8,8,15), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=128, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=64, activation='relu',\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
        "    model.add(tf.keras.layers.Dense(units=33))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_model_eg_bin3b(my_learning_rate):\n",
        "    \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "    # L2 reg: 0.1 in both destroyed accuracy\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=256, kernel_size=(3,3), input_shape=(8,8,15), strides=(1, 1), padding='same',\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(l=0.005)))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=128, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=128, kernel_size=(3,3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=64, activation='relu',\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(l=0.005)))\n",
        "    model.add(tf.keras.layers.Dense(units=33))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApvgUTov32Kg"
      },
      "source": [
        "train_model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpoGTNUy34On"
      },
      "source": [
        "def train_model(model, tb_callback, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "    \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "    history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                        epochs=epochs, shuffle=True, callbacks=[tb_callback],\n",
        "                        validation_split=validation_split)\n",
        "\n",
        "    # To track the progression of training, gather a snapshot\n",
        "    # of the model's metrics at each epoch.\n",
        "    epochs = history.epoch\n",
        "    hist = pd.DataFrame(history.history)\n",
        "\n",
        "    return epochs, hist"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGWkQVsp4I8Y"
      },
      "source": [
        "main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yfqZwQ8y4IAv",
        "outputId": "7f0d34aa-d03d-446a-e598-3bed4f6260b3"
      },
      "source": [
        "def ask_gen_training():\n",
        "    yes_no = input(\"Do you need to generate endgame training data? \")\n",
        "    if len(yes_no) == 0:\n",
        "        pass\n",
        "    elif yes_no[0].lower() == \"y\":\n",
        "        generate_training()\n",
        "\n",
        "\n",
        "def ask_train_net():\n",
        "    yes_no = input(\"Do you want to train a net? \")\n",
        "    if len(yes_no) == 0:\n",
        "        pass\n",
        "    elif yes_no[0].lower() == \"n\":\n",
        "        return\n",
        "\n",
        "    # Get the data to use for training\n",
        "    plane_version=\"v1\"\n",
        "    material_balance, target_count = ask_for_input()\n",
        "    material_balance = material_balance.lower()\n",
        "    input_file = \"train_\"+material_balance+str(int(target_count/1000))+\"K\"+plane_version+\".npz\"\n",
        "\n",
        "    (x_train, y_train4) = import_endgame(input_file)\n",
        "    # Print a sample image\n",
        "    print(x_train.shape)\n",
        "    print(y_train4.shape)\n",
        "    print(y_train4[18])\n",
        "    y_train = y_train4[:, 3]  # Column 3 is the score (-2000, 2000)\n",
        "\n",
        "    ##############\n",
        "    # The following variables are the hyperparameters.\n",
        "    learning_rate = 0.003\n",
        "    epochs = 20\n",
        "    batch_size = 2000\n",
        "    validation_split = 0.2\n",
        "\n",
        "    # Establish the model's topography.\n",
        "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/bin3/\", histogram_freq=1)\n",
        "    my_model = create_model_eg_bin3b(learning_rate)\n",
        "    my_model.summary()\n",
        "    # Train the model on the normalized training set.\n",
        "    epochs, hist = train_model(my_model, tb_callback, x_train, y_train,\n",
        "                                     epochs, batch_size, validation_split)\n",
        "\n",
        "    # Plot a graph of the metric vs. epochs.\n",
        "    # list_of_metrics_to_plot = ['accuracy','val_accuracy']\n",
        "    list_of_metrics_to_plot = ['loss', 'val_loss']\n",
        "    plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "    return my_model\n",
        "\n",
        "\n",
        "def set_options():\n",
        "    print(f\"Using Tensorflow {tf.__version__}\")\n",
        "    # The following lines adjust the granularity of reporting.\n",
        "    pd.options.display.max_rows = 10\n",
        "    pd.options.display.float_format = \"{:.6f}\".format  # was .3f\n",
        "    # The following line improves formatting when ouputting NumPy arrays.\n",
        "    np.set_printoptions(linewidth=200)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    set_options()\n",
        "\n",
        "    print(\"Welcome to chess_pos_gen\")\n",
        "    print(\"We are going to generate a file of chess endgame training examples\")\n",
        "    print(\"to use in training a neural net.\")\n",
        "    ask_gen_training()\n",
        "    model = ask_train_net()\n",
        "    for layer in model.layers:\n",
        "      print(layer.name, layer)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Tensorflow 2.6.0\n",
            "Welcome to chess_pos_gen\n",
            "We are going to generate a file of chess endgame training examples\n",
            "to use in training a neural net.\n",
            "Do you need to generate endgame training data? n\n",
            "Do you want to train a net? y\n",
            "Please enter the endgame (e.g. KRkp): krk\n",
            "Please enter the number of training examples: 150000\n",
            "frequency list:\n",
            "Frequency of unique values of the said array:\n",
            "[[    0     1     2     3     4     5     6     7     8     9    10    11    12    13    14    15    16    17    18    19    20    21    22    23    24    25    26    27    28    29    30    31\n",
            "     32]\n",
            " [ 1122  6389 13597 12549 10771  8557  6010  5145  4297  1986  1743  1376   616   258   788   228  8478   537  1831  1393   714  1749  3275  4238  6615  7488  7067  7697  8084  6855  6173  2015\n",
            "    359]]\n",
            "(150000, 8, 8, 15)\n",
            "(150000, 4)\n",
            "[ 1  0  0 24]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 256)         34816     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 128)         295040    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 33)                2145      \n",
            "=================================================================\n",
            "Total params: 487,841\n",
            "Trainable params: 487,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "60/60 [==============================] - 4s 52ms/step - loss: 3.2151 - accuracy: 0.1182 - val_loss: 2.8963 - val_accuracy: 0.1410\n",
            "Epoch 2/20\n",
            "60/60 [==============================] - 2s 37ms/step - loss: 2.2731 - accuracy: 0.2546 - val_loss: 1.7995 - val_accuracy: 0.3367\n",
            "Epoch 3/20\n",
            "60/60 [==============================] - 2s 39ms/step - loss: 2.0477 - accuracy: 0.3332 - val_loss: 1.6550 - val_accuracy: 0.3976\n",
            "Epoch 4/20\n",
            "60/60 [==============================] - 2s 37ms/step - loss: 1.5237 - accuracy: 0.4473 - val_loss: 1.4744 - val_accuracy: 0.4623\n",
            "Epoch 5/20\n",
            "60/60 [==============================] - 2s 39ms/step - loss: 1.4051 - accuracy: 0.4822 - val_loss: 1.3941 - val_accuracy: 0.4821\n",
            "Epoch 6/20\n",
            "60/60 [==============================] - 2s 37ms/step - loss: 1.3394 - accuracy: 0.5030 - val_loss: 1.3405 - val_accuracy: 0.4992\n",
            "Epoch 7/20\n",
            "60/60 [==============================] - 2s 39ms/step - loss: 1.2897 - accuracy: 0.5170 - val_loss: 1.3037 - val_accuracy: 0.5062\n",
            "Epoch 8/20\n",
            "60/60 [==============================] - 2s 37ms/step - loss: 1.2358 - accuracy: 0.5348 - val_loss: 1.2785 - val_accuracy: 0.5142\n",
            "Epoch 9/20\n",
            "60/60 [==============================] - 2s 37ms/step - loss: 1.1949 - accuracy: 0.5504 - val_loss: 1.2784 - val_accuracy: 0.5196\n",
            "Epoch 10/20\n",
            "60/60 [==============================] - 2s 37ms/step - loss: 1.1633 - accuracy: 0.5614 - val_loss: 1.1957 - val_accuracy: 0.5480\n",
            "Epoch 11/20\n",
            "60/60 [==============================] - 2s 37ms/step - loss: 1.1198 - accuracy: 0.5794 - val_loss: 1.1813 - val_accuracy: 0.5489\n",
            "Epoch 12/20\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 1.0909 - accuracy: 0.5921 - val_loss: 1.1553 - val_accuracy: 0.5642\n",
            "Epoch 13/20\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 1.0589 - accuracy: 0.6035 - val_loss: 1.1345 - val_accuracy: 0.5757\n",
            "Epoch 14/20\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 1.0310 - accuracy: 0.6179 - val_loss: 1.1188 - val_accuracy: 0.5792\n",
            "Epoch 15/20\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 1.0081 - accuracy: 0.6271 - val_loss: 1.1056 - val_accuracy: 0.5863\n",
            "Epoch 16/20\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.9748 - accuracy: 0.6432 - val_loss: 1.0837 - val_accuracy: 0.5933\n",
            "Epoch 17/20\n",
            "60/60 [==============================] - 2s 41ms/step - loss: 0.9567 - accuracy: 0.6486 - val_loss: 1.0888 - val_accuracy: 0.5963\n",
            "Epoch 18/20\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 0.9399 - accuracy: 0.6558 - val_loss: 1.0967 - val_accuracy: 0.5890\n",
            "Epoch 19/20\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 0.9125 - accuracy: 0.6689 - val_loss: 1.0806 - val_accuracy: 0.6017\n",
            "Epoch 20/20\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.8868 - accuracy: 0.6809 - val_loss: 1.0523 - val_accuracy: 0.6129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "conv2d_6 <keras.layers.convolutional.Conv2D object at 0x7f6490284f10>\n",
            "max_pooling2d_6 <keras.layers.pooling.MaxPooling2D object at 0x7f64901fca90>\n",
            "conv2d_7 <keras.layers.convolutional.Conv2D object at 0x7f649014bbd0>\n",
            "max_pooling2d_7 <keras.layers.pooling.MaxPooling2D object at 0x7f6490028c50>\n",
            "conv2d_8 <keras.layers.convolutional.Conv2D object at 0x7f6490218cd0>\n",
            "max_pooling2d_8 <keras.layers.pooling.MaxPooling2D object at 0x7f649023e350>\n",
            "flatten_2 <keras.layers.core.Flatten object at 0x7f645410c950>\n",
            "dense_4 <keras.layers.core.Dense object at 0x7f6490227b50>\n",
            "dense_5 <keras.layers.core.Dense object at 0x7f64a7e00a50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY5So56UlVmf",
        "outputId": "89e708a5-e33f-4103-83c4-2da27e4d0743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.layers[0].weights)\n",
        "print(model.layers[0].bias.numpy())\n",
        "print(model.layers[0].bias_initializer)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 15, 256) dtype=float32, numpy=\n",
            "array([[[[-1.59897174e-30,  3.17626097e-30, -2.10452820e-29, ...,  1.21046954e-30,  1.40233561e-30, -9.80286493e-31],\n",
            "         [-1.49012585e-30, -4.99786231e-30, -1.39917216e-29, ..., -4.94709807e-31,  1.34632208e-30,  1.06308354e-29],\n",
            "         [ 6.26461452e-30, -1.03641738e-31,  4.05752099e-30, ...,  6.28824139e-30, -1.13009431e-29,  1.26643300e-29],\n",
            "         ...,\n",
            "         [-1.11022741e-02,  2.56692190e-02,  2.24351417e-02, ...,  8.55909567e-03,  3.61429265e-05,  1.43173113e-02],\n",
            "         [-1.47080351e-29,  1.82480990e-29,  8.83010141e-30, ..., -1.16073037e-29,  2.01387517e-30, -5.04405566e-31],\n",
            "         [-9.81898792e-03,  7.60208629e-03,  1.98185910e-03, ..., -3.30045616e-04, -1.57938804e-02, -7.42611708e-03]],\n",
            "\n",
            "        [[ 2.49317063e-29,  5.42766781e-30, -1.06806131e-29, ..., -7.77274782e-30,  3.20483244e-30,  1.96515843e-29],\n",
            "         [-7.99565897e-31, -5.70071013e-30, -2.41423368e-30, ..., -1.00741987e-29,  7.73431799e-30,  1.98845631e-29],\n",
            "         [ 3.16668624e-30, -2.03478712e-30,  2.52586787e-08, ..., -1.14966522e-29, -1.05104023e-29,  1.51828551e-29],\n",
            "         ...,\n",
            "         [-8.38202052e-03,  2.30960965e-01,  7.67405927e-02, ..., -9.71084088e-03, -7.09981285e-03,  2.24439427e-02],\n",
            "         [-4.00212267e-30,  1.41877301e-29,  1.73335380e-29, ..., -1.46951163e-30,  9.15765545e-30, -1.72439838e-29],\n",
            "         [ 2.47635599e-03,  1.36400508e-02,  1.52270962e-02, ..., -3.92567785e-03,  1.28170699e-02, -5.83723467e-03]],\n",
            "\n",
            "        [[-1.78486942e-29, -1.68553748e-29, -7.55502520e-30, ...,  7.58924055e-30, -2.77829463e-30, -1.50046682e-31],\n",
            "         [-9.45107840e-30,  1.94671178e-29, -6.04872830e-30, ...,  1.68643755e-31, -2.32903235e-30, -2.52239910e-30],\n",
            "         [-7.65107644e-30, -1.62949321e-29, -8.77531246e-30, ...,  7.42992928e-30,  1.58889672e-29,  7.69955495e-30],\n",
            "         ...,\n",
            "         [-3.55159421e-03,  1.00744050e-02,  1.48860607e-02, ...,  4.94183833e-03,  7.51369353e-03,  3.09638493e-02],\n",
            "         [-3.85064979e-30, -4.53267500e-30, -7.72666844e-30, ..., -5.52175212e-30,  2.21121689e-29, -1.55143332e-29],\n",
            "         [-3.36200930e-04, -8.50444252e-04, -8.87710601e-03, ..., -1.88399553e-02, -9.52537521e-04,  1.47161190e-03]]],\n",
            "\n",
            "\n",
            "       [[[ 1.02247696e-30,  5.20674483e-30, -5.88967734e-30, ...,  1.30216156e-29,  1.17371783e-29,  5.56574946e-31],\n",
            "         [-9.74168870e-07,  1.42901158e-29,  5.21833953e-30, ..., -1.13525652e-30, -1.55880058e-30, -5.03637827e-30],\n",
            "         [ 2.95246565e-30, -2.90799849e-30, -1.56022248e-29, ...,  1.71043403e-29, -3.09543210e-30,  2.63681269e-30],\n",
            "         ...,\n",
            "         [-6.21920126e-03, -1.74749270e-02,  7.16880546e-04, ..., -7.52133643e-03, -2.83942488e-03, -1.00487494e-03],\n",
            "         [ 2.55125307e-30, -1.93547007e-30, -2.47031947e-29, ...,  1.39174363e-29, -3.42256860e-30,  1.81730268e-29],\n",
            "         [ 1.97312124e-02, -4.35125781e-03, -2.83295615e-03, ...,  1.12910615e-02, -1.78921949e-02, -3.84253450e-03]],\n",
            "\n",
            "        [[-4.37460091e-30, -2.24423726e-30,  7.00323047e-30, ...,  8.46698989e-31,  1.90397171e-30,  1.46926818e-29],\n",
            "         [ 4.10784682e-31,  6.47440697e-30,  2.24173092e-30, ..., -6.45277261e-30, -1.64551289e-29,  1.60627993e-30],\n",
            "         [-1.03405992e-29, -2.59711785e-30, -9.56181260e-30, ...,  6.70527406e-30,  1.20036405e-30,  8.53965613e-31],\n",
            "         ...,\n",
            "         [ 6.77170930e-03, -3.32131959e-03,  9.16347988e-30, ..., -8.77460465e-03, -4.65185987e-03,  2.29455337e-01],\n",
            "         [ 7.13813885e-30,  7.84347007e-30,  5.64181391e-30, ...,  2.48539773e-30, -2.30173304e-30,  5.64615929e-30],\n",
            "         [-3.01501229e-02, -1.17379269e-02,  1.04726888e-02, ..., -3.30462726e-03,  7.71420915e-03, -6.35699788e-03]],\n",
            "\n",
            "        [[ 6.84136659e-30,  2.19872889e-30, -4.44934129e-30, ...,  1.70674934e-30, -6.48983021e-30, -8.02547722e-30],\n",
            "         [-4.54102909e-30,  2.15838533e-29,  9.36773303e-30, ..., -2.47949014e-13,  1.57104613e-30,  8.02818631e-31],\n",
            "         [ 9.77823333e-08,  1.09558406e-29, -1.67823685e-29, ..., -8.14359541e-31,  2.99552373e-30,  2.25674151e-30],\n",
            "         ...,\n",
            "         [-6.25276426e-03, -1.72200091e-02,  5.86659554e-03, ..., -1.22876931e-02, -1.66208411e-04, -2.37970753e-03],\n",
            "         [ 6.06027711e-30, -1.13907193e-29,  6.24087292e-30, ..., -8.68126615e-30,  1.62560675e-30, -1.39687458e-29],\n",
            "         [-2.04456504e-02, -2.75588445e-02, -4.12213430e-03, ..., -2.75793541e-02,  1.60632050e-03, -1.16604762e-02]]],\n",
            "\n",
            "\n",
            "       [[[ 1.06350717e-30,  3.24373359e-30, -1.44344161e-30, ..., -4.96245455e-04,  1.84729753e-29, -5.91840378e-30],\n",
            "         [-2.83013073e-30, -1.65913730e-30,  1.04418701e-29, ..., -9.08712729e-30, -5.53335697e-30,  6.91328202e-30],\n",
            "         [-4.00964132e-30, -1.29624395e-30, -1.75180511e-29, ...,  1.13823964e-29, -2.60375535e-30,  4.57265422e-30],\n",
            "         ...,\n",
            "         [-1.12517802e-02, -8.15048988e-04,  2.98121776e-02, ..., -1.19061489e-03, -9.32893157e-03,  3.55019718e-02],\n",
            "         [ 8.86795759e-31, -4.58509226e-30, -6.95511833e-30, ..., -1.15376211e-29, -3.45682156e-30,  3.97438477e-30],\n",
            "         [-1.91516932e-02,  6.62251888e-03, -9.25672986e-03, ..., -1.45443566e-02, -1.71393864e-02,  7.14019639e-03]],\n",
            "\n",
            "        [[ 9.09782975e-30, -1.34265965e-29, -9.28737511e-30, ...,  4.15584423e-30, -1.02301231e-29,  5.94035224e-30],\n",
            "         [-6.09077150e-30, -2.06503776e-30,  3.65430650e-30, ..., -1.16745931e-29, -1.09388946e-30, -3.79497875e-30],\n",
            "         [-6.02183675e-30,  2.27085783e-29,  2.52045173e-30, ...,  3.92256935e-30,  2.38624932e-29,  5.89433154e-30],\n",
            "         ...,\n",
            "         [-1.00884605e-02, -2.00203341e-02,  9.77663547e-02, ..., -1.81575343e-02, -7.87537731e-03,  1.38640646e-02],\n",
            "         [-4.80529113e-31,  5.34404934e-30, -6.27560436e-30, ...,  7.78830421e-30, -9.36176942e-30, -4.88915146e-30],\n",
            "         [-1.47261359e-02,  1.21199666e-03,  1.96886458e-03, ..., -2.22958717e-03,  1.59475710e-02, -1.45924194e-02]],\n",
            "\n",
            "        [[-4.25127444e-30,  1.26084382e-29,  9.93288288e-30, ..., -1.41845147e-29, -4.67198293e-30, -4.82076666e-30],\n",
            "         [-3.39498379e-30,  1.08210631e-30,  2.10756906e-29, ..., -1.01869928e-29,  2.56721120e-30, -1.62268400e-29],\n",
            "         [-2.83901784e-30,  1.02314599e-29,  1.12098015e-29, ..., -1.37137888e-29,  1.48459091e-29,  5.66674041e-30],\n",
            "         ...,\n",
            "         [-1.79985203e-02, -2.47531533e-02,  1.95374917e-02, ..., -7.25039653e-03, -1.38816591e-02, -1.15290554e-02],\n",
            "         [ 8.81203604e-30, -6.15626403e-30, -1.08931335e-29, ...,  9.19314071e-31, -1.88174046e-04, -1.69887823e-30],\n",
            "         [ 1.86791793e-02, -5.66852465e-03, -1.72004607e-02, ..., -5.11651067e-03,  2.42921477e-03,  2.94387504e-03]]]], dtype=float32)>, <tf.Variable 'conv2d_6/bias:0' shape=(256,) dtype=float32, numpy=\n",
            "array([ 3.08291316e-02, -1.18612796e-02, -1.16544422e-02, -1.58806909e-02, -1.35823376e-02, -1.01050483e-02, -1.12888319e-02, -1.81052573e-02, -7.15529826e-03,  1.60284340e-02, -1.54150352e-02,\n",
            "       -1.84256714e-02, -1.71673577e-02, -7.43306754e-03,  1.34406833e-03, -1.88323073e-02, -2.64989324e-02, -1.47673823e-02,  1.72387809e-02, -4.96399216e-03,  1.92240793e-02,  2.65380833e-03,\n",
            "        3.41367647e-02, -7.05719320e-03, -1.10776862e-03,  5.74149285e-03, -3.00440267e-02, -2.52751447e-03, -8.82726070e-03, -2.46353205e-02, -7.09725497e-03, -1.49561083e-02, -9.44886636e-03,\n",
            "        5.98614803e-03, -2.03098003e-02, -1.26711950e-02, -1.14469603e-02,  2.66603511e-02, -9.19256825e-03, -5.74119482e-03,  1.01498039e-02,  3.45720761e-02,  4.27014828e-02, -9.18933935e-03,\n",
            "       -4.21316624e-02,  3.21253436e-03, -2.01951563e-02, -5.64484391e-03, -2.59453412e-02,  1.65908355e-02, -8.89431499e-03,  5.35687478e-03, -1.87437497e-02,  1.95702240e-02,  2.94379275e-02,\n",
            "        2.81065889e-03,  3.64207523e-03,  3.17854919e-02, -9.43197962e-03, -1.52631069e-03,  2.89128106e-02, -2.13776855e-03,  5.48413489e-03,  1.35714961e-02,  6.15599891e-03,  7.20435381e-03,\n",
            "       -8.05492047e-03, -2.46644542e-02, -3.40862721e-02,  8.05924553e-03, -3.25420052e-02,  5.65843694e-02,  6.35322323e-03, -2.67915726e-02,  8.53382866e-04, -6.67838752e-03, -1.51156504e-02,\n",
            "        1.29752820e-02,  1.82113759e-02,  2.52136029e-02,  3.04732602e-02,  1.58257578e-02, -7.17822881e-03,  1.37318345e-02,  3.99173563e-03, -2.40553333e-03,  2.89534014e-02, -1.62596777e-02,\n",
            "       -2.16042493e-02,  4.65435721e-03, -1.72100286e-03,  5.93524538e-02, -1.23460032e-02, -3.90140489e-02, -1.42331999e-02,  1.77612377e-03,  2.51568537e-02, -9.46283434e-03, -7.35138403e-03,\n",
            "       -1.21829696e-02, -1.61753241e-02, -8.06975458e-03,  1.24179255e-02, -8.82466231e-03,  4.82166046e-03,  1.18621076e-02,  1.81310298e-03, -2.88232975e-02, -1.25024971e-02, -1.83691159e-02,\n",
            "        1.54245896e-02, -3.90106700e-02,  1.25144245e-02,  1.23719382e-03,  7.79321557e-03,  2.90834974e-03,  6.27394440e-03, -1.60182244e-03, -1.59270708e-02,  3.14642899e-02,  1.04254065e-03,\n",
            "       -1.05820352e-03,  1.91742573e-02,  5.94445225e-03,  2.12398358e-02,  3.30588385e-03, -1.67162325e-02,  1.34041440e-02,  1.22132688e-03, -1.37588875e-02,  1.08637856e-02,  1.13517866e-02,\n",
            "        2.68082395e-02,  1.59893427e-02, -9.32293246e-04,  9.91680194e-04, -3.38431448e-02,  7.58571550e-03, -2.69797500e-02, -2.32302980e-03, -2.70542186e-02, -1.59914605e-02, -7.43673602e-03,\n",
            "        3.40915136e-02, -3.08464821e-02, -5.20687969e-03, -6.34079427e-02, -2.32448336e-02, -3.01166112e-03,  1.69878434e-02, -3.23217735e-03,  1.84517521e-02,  1.88457267e-03, -3.61970663e-02,\n",
            "       -4.96040806e-02,  2.33525578e-02,  7.47131510e-03, -2.40799896e-02, -1.06126722e-02, -5.95714385e-03, -6.09573862e-03,  6.96928846e-03,  5.65658230e-03,  2.22350769e-02, -1.03996554e-02,\n",
            "       -1.12084514e-02, -1.22616906e-02, -6.21917844e-03, -2.17881091e-02, -1.30651165e-02, -1.12004355e-02,  5.13238367e-03, -1.63216516e-02, -1.82003889e-03, -5.04765660e-03, -2.80406978e-03,\n",
            "       -4.66935933e-02,  1.19076623e-02, -1.55127607e-02, -1.33078871e-02,  2.39614304e-02,  8.32588132e-03, -5.31624723e-03, -2.61564218e-02, -1.27195064e-02, -9.77669377e-03, -3.16208340e-02,\n",
            "       -4.06445470e-03,  9.46737081e-03, -2.51525268e-02, -1.83960795e-02,  4.54477780e-03, -4.21244744e-03, -1.87340602e-02, -1.83378812e-03, -6.42410992e-03,  4.75999899e-03,  2.17624083e-02,\n",
            "        2.95610968e-02, -1.83786955e-02,  1.25509147e-02,  1.93807073e-02, -7.06403423e-03,  1.89619837e-03, -1.28248278e-02, -1.37876263e-02, -2.05934998e-02, -1.26009705e-02,  2.34545153e-02,\n",
            "       -2.35464498e-02,  6.17606333e-03, -4.12553363e-03,  2.76312996e-02, -1.07320584e-02, -1.99537314e-02, -1.88031718e-02, -4.36672568e-02,  6.22661319e-03, -1.79166049e-02, -1.69260669e-02,\n",
            "       -1.37873627e-02,  2.55400757e-03,  9.06786323e-03,  5.25390715e-05,  7.74516491e-03,  1.77084294e-03, -4.32721991e-03, -1.86157727e-03,  9.33439378e-03, -4.00670543e-02, -7.69987237e-03,\n",
            "       -2.15772651e-02, -2.85718739e-02, -9.97823384e-03,  2.59088166e-02,  2.69098058e-02, -7.28579762e-05, -2.05128510e-02, -2.38723066e-02, -7.42086582e-03,  3.14638615e-02, -5.99820167e-02,\n",
            "       -2.67303064e-02,  1.09531106e-02, -9.00619756e-03, -1.66051905e-03, -2.36281715e-02,  3.82743008e-03, -8.21544137e-03, -5.61096286e-03,  1.49379997e-02,  1.68488231e-02,  2.62395311e-02,\n",
            "        1.77694682e-03, -2.62710433e-02, -5.82397857e-04], dtype=float32)>]\n",
            "[ 3.08291316e-02 -1.18612796e-02 -1.16544422e-02 -1.58806909e-02 -1.35823376e-02 -1.01050483e-02 -1.12888319e-02 -1.81052573e-02 -7.15529826e-03  1.60284340e-02 -1.54150352e-02 -1.84256714e-02\n",
            " -1.71673577e-02 -7.43306754e-03  1.34406833e-03 -1.88323073e-02 -2.64989324e-02 -1.47673823e-02  1.72387809e-02 -4.96399216e-03  1.92240793e-02  2.65380833e-03  3.41367647e-02 -7.05719320e-03\n",
            " -1.10776862e-03  5.74149285e-03 -3.00440267e-02 -2.52751447e-03 -8.82726070e-03 -2.46353205e-02 -7.09725497e-03 -1.49561083e-02 -9.44886636e-03  5.98614803e-03 -2.03098003e-02 -1.26711950e-02\n",
            " -1.14469603e-02  2.66603511e-02 -9.19256825e-03 -5.74119482e-03  1.01498039e-02  3.45720761e-02  4.27014828e-02 -9.18933935e-03 -4.21316624e-02  3.21253436e-03 -2.01951563e-02 -5.64484391e-03\n",
            " -2.59453412e-02  1.65908355e-02 -8.89431499e-03  5.35687478e-03 -1.87437497e-02  1.95702240e-02  2.94379275e-02  2.81065889e-03  3.64207523e-03  3.17854919e-02 -9.43197962e-03 -1.52631069e-03\n",
            "  2.89128106e-02 -2.13776855e-03  5.48413489e-03  1.35714961e-02  6.15599891e-03  7.20435381e-03 -8.05492047e-03 -2.46644542e-02 -3.40862721e-02  8.05924553e-03 -3.25420052e-02  5.65843694e-02\n",
            "  6.35322323e-03 -2.67915726e-02  8.53382866e-04 -6.67838752e-03 -1.51156504e-02  1.29752820e-02  1.82113759e-02  2.52136029e-02  3.04732602e-02  1.58257578e-02 -7.17822881e-03  1.37318345e-02\n",
            "  3.99173563e-03 -2.40553333e-03  2.89534014e-02 -1.62596777e-02 -2.16042493e-02  4.65435721e-03 -1.72100286e-03  5.93524538e-02 -1.23460032e-02 -3.90140489e-02 -1.42331999e-02  1.77612377e-03\n",
            "  2.51568537e-02 -9.46283434e-03 -7.35138403e-03 -1.21829696e-02 -1.61753241e-02 -8.06975458e-03  1.24179255e-02 -8.82466231e-03  4.82166046e-03  1.18621076e-02  1.81310298e-03 -2.88232975e-02\n",
            " -1.25024971e-02 -1.83691159e-02  1.54245896e-02 -3.90106700e-02  1.25144245e-02  1.23719382e-03  7.79321557e-03  2.90834974e-03  6.27394440e-03 -1.60182244e-03 -1.59270708e-02  3.14642899e-02\n",
            "  1.04254065e-03 -1.05820352e-03  1.91742573e-02  5.94445225e-03  2.12398358e-02  3.30588385e-03 -1.67162325e-02  1.34041440e-02  1.22132688e-03 -1.37588875e-02  1.08637856e-02  1.13517866e-02\n",
            "  2.68082395e-02  1.59893427e-02 -9.32293246e-04  9.91680194e-04 -3.38431448e-02  7.58571550e-03 -2.69797500e-02 -2.32302980e-03 -2.70542186e-02 -1.59914605e-02 -7.43673602e-03  3.40915136e-02\n",
            " -3.08464821e-02 -5.20687969e-03 -6.34079427e-02 -2.32448336e-02 -3.01166112e-03  1.69878434e-02 -3.23217735e-03  1.84517521e-02  1.88457267e-03 -3.61970663e-02 -4.96040806e-02  2.33525578e-02\n",
            "  7.47131510e-03 -2.40799896e-02 -1.06126722e-02 -5.95714385e-03 -6.09573862e-03  6.96928846e-03  5.65658230e-03  2.22350769e-02 -1.03996554e-02 -1.12084514e-02 -1.22616906e-02 -6.21917844e-03\n",
            " -2.17881091e-02 -1.30651165e-02 -1.12004355e-02  5.13238367e-03 -1.63216516e-02 -1.82003889e-03 -5.04765660e-03 -2.80406978e-03 -4.66935933e-02  1.19076623e-02 -1.55127607e-02 -1.33078871e-02\n",
            "  2.39614304e-02  8.32588132e-03 -5.31624723e-03 -2.61564218e-02 -1.27195064e-02 -9.77669377e-03 -3.16208340e-02 -4.06445470e-03  9.46737081e-03 -2.51525268e-02 -1.83960795e-02  4.54477780e-03\n",
            " -4.21244744e-03 -1.87340602e-02 -1.83378812e-03 -6.42410992e-03  4.75999899e-03  2.17624083e-02  2.95610968e-02 -1.83786955e-02  1.25509147e-02  1.93807073e-02 -7.06403423e-03  1.89619837e-03\n",
            " -1.28248278e-02 -1.37876263e-02 -2.05934998e-02 -1.26009705e-02  2.34545153e-02 -2.35464498e-02  6.17606333e-03 -4.12553363e-03  2.76312996e-02 -1.07320584e-02 -1.99537314e-02 -1.88031718e-02\n",
            " -4.36672568e-02  6.22661319e-03 -1.79166049e-02 -1.69260669e-02 -1.37873627e-02  2.55400757e-03  9.06786323e-03  5.25390715e-05  7.74516491e-03  1.77084294e-03 -4.32721991e-03 -1.86157727e-03\n",
            "  9.33439378e-03 -4.00670543e-02 -7.69987237e-03 -2.15772651e-02 -2.85718739e-02 -9.97823384e-03  2.59088166e-02  2.69098058e-02 -7.28579762e-05 -2.05128510e-02 -2.38723066e-02 -7.42086582e-03\n",
            "  3.14638615e-02 -5.99820167e-02 -2.67303064e-02  1.09531106e-02 -9.00619756e-03 -1.66051905e-03 -2.36281715e-02  3.82743008e-03 -8.21544137e-03 -5.61096286e-03  1.49379997e-02  1.68488231e-02\n",
            "  2.62395311e-02  1.77694682e-03 -2.62710433e-02 -5.82397857e-04]\n",
            "<keras.initializers.initializers_v2.Zeros object at 0x7f649015cbd0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaRhrs1ciDmP"
      },
      "source": [
        ""
      ],
      "execution_count": 57,
      "outputs": []
    }
  ]
}